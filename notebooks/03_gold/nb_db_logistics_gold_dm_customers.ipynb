{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aa783a9a-2e72-4e70-ad51-8bc6ecb727a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Layer: Gold (Business)\n",
    "**Project:** Lean Logistics Data Pipeline  \n",
    "**Business Domain:** E-commerce (Olist Dataset)\\\n",
    "**Table Name:** `dm_customers`\n",
    "\n",
    "---\n",
    "## üìë Notebook Information\n",
    "| Version | Date | Author | Summary of Changes |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| v1.0 | 2026-02-20 | T√°ssia Marchito | Consolidated script: Customer and Geolocation join, Business comments, and Tags. |\n",
    "\n",
    "---\n",
    "## üéØ Objectives\n",
    "This notebook creates the Customer Dimension by enriching customer data with geographic coordinates.\n",
    "* **Data Enrichment:** Joining `tb_customers` with aggregated `tb_geolocation` from Silver.\n",
    "* **Data Quality:** Ensuring one unique record per `cd_customer_id`.\n",
    "* **Governance:** Applying standardized prefixes, column comments, and discovery tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02ceb3e4-176e-4eb0-8a38-4770f0d93309",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Importando recursos"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, current_timestamp, avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd89bfcc-b9cc-4a20-92b0-471d4ec03ea1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "dm_products"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Configura√ß√µes\n",
    "source_customers = \"cat_tm_services_silver.db_logistics.tb_customers\"\n",
    "source_geo = \"cat_tm_services_silver.db_logistics.tb_geolocation\"\n",
    "target_table = \"cat_tm_services_gold.db_logistics.dm_customers\"\n",
    "\n",
    "print(f\"üöÄ Building {target_table}...\")\n",
    "\n",
    "# 2. Prepara√ß√£o da Geolocaliza√ß√£o (Agregando para evitar duplicidade de CEP)\n",
    "df_geo_agg = spark.read.table(source_geo) \\\n",
    "    .groupBy(\"cd_geolocation_zip_code_prefix\") \\\n",
    "    .agg(\n",
    "        avg(\"cd_geolocation_lat\").alias(\"vl_latitude\"),\n",
    "        avg(\"cd_geolocation_lng\").alias(\"vl_longitude\")\n",
    "    )\n",
    "\n",
    "# 3. Join com Clientes\n",
    "df_customers = spark.read.table(source_customers)\n",
    "\n",
    "dm_customers = df_customers.join(\n",
    "    df_geo_agg, \n",
    "    df_customers.cd_customer_zip_code_prefix == df_geo_agg.cd_geolocation_zip_code_prefix, \n",
    "    \"left\"\n",
    ").select(\n",
    "    col(\"cd_customer_id\"),\n",
    "    col(\"cd_customer_unique_id\"),\n",
    "    col(\"cd_customer_zip_code_prefix\").alias(\"cd_zip_code\"),\n",
    "    col(\"nm_customer_city\").alias(\"nm_city\"),\n",
    "    col(\"nm_customer_state\").alias(\"nm_state\"),\n",
    "    col(\"vl_latitude\"),\n",
    "    col(\"vl_longitude\")\n",
    ").withColumn(\"ts_gold_at\", current_timestamp())\n",
    "\n",
    "# 4. Escrita da Tabela\n",
    "dm_customers.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(target_table)\n",
    "\n",
    "# 5. Aplica√ß√£o de Governan√ßa (Tags e Coment√°rios)\n",
    "print(f\"üìù Applying metadata to {target_table}...\")\n",
    "\n",
    "# Tags\n",
    "spark.sql(f\"ALTER TABLE {target_table} SET TAGS ('quality' = 'gold', 'domain' = 'logistics', 'type' = 'dimension')\")\n",
    "\n",
    "# Coment√°rios\n",
    "spark.sql(f\"ALTER TABLE {target_table} ALTER COLUMN cd_customer_id COMMENT 'Unique identifier for the customer order point'\")\n",
    "spark.sql(f\"ALTER TABLE {target_table} ALTER COLUMN cd_customer_unique_id COMMENT 'Global unique identifier for the customer'\")\n",
    "spark.sql(f\"ALTER TABLE {target_table} ALTER COLUMN cd_zip_code COMMENT 'Customer zip code prefix'\")\n",
    "spark.sql(f\"ALTER TABLE {target_table} ALTER COLUMN nm_city COMMENT 'City name'\")\n",
    "spark.sql(f\"ALTER TABLE {target_table} ALTER COLUMN nm_state COMMENT 'State abbreviation'\")\n",
    "spark.sql(f\"ALTER TABLE {target_table} ALTER COLUMN vl_latitude COMMENT 'Average latitude for the zip code'\")\n",
    "spark.sql(f\"ALTER TABLE {target_table} ALTER COLUMN vl_longitude COMMENT 'Average longitude for the zip code'\")\n",
    "spark.sql(f\"ALTER TABLE {target_table} ALTER COLUMN ts_gold_at COMMENT 'Timestamp of Gold layer processing'\")\n",
    "\n",
    "# Constraints\n",
    "spark.sql(f\"ALTER TABLE {target_table} ALTER COLUMN cd_customer_id SET NOT NULL\")\n",
    "try:\n",
    "    spark.sql(f\"ALTER TABLE {target_table} ADD CONSTRAINT pk_dm_customers PRIMARY KEY(cd_customer_id) RELY\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(f\"‚úÖ Table {target_table} is complete!\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "nb_db_logistics_gold_dm_customers",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
