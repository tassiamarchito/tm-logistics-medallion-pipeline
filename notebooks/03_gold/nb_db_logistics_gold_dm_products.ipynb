{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aa783a9a-2e72-4e70-ad51-8bc6ecb727a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Layer: Gold (Business)\n",
    "**Project:** Lean Logistics Data Pipeline\\\n",
    "**Business Domain:** E-commerce (Olist Dataset)\\\n",
    "**Table Name:** `dm_products`\n",
    "\n",
    "---\n",
    "## üìë Notebook Information\n",
    "| Version | Date | Author | Summary of Changes |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| v1.0 | 2026-02-20 | T√°ssia Marchito | Initial creation of Product Dimension (`dm_products`). |\n",
    "| v1.1 | 2026-02-20 | T√°ssia Marchito | Added column comments, table tags, and enforced PK constraint. |\n",
    "\n",
    "---\n",
    "## üéØ Objectives\n",
    "This notebook creates the Product Dimension by joining the refined products table with their respective category translations.\n",
    "* **Dimensional Modeling:** Implementing the `dm_` prefix for analytical dimensions.\n",
    "* **Enrichment:** Joining `tb_products` with `tb_product_category_name_translation` from the Silver layer.\n",
    "* **Standardization:** Providing English category names as the primary descriptor for business users.\n",
    "* **Metadata Management:** Added detailed comments to each column for business clarity.\n",
    "* **Governance:** Applied table-level tags and enforced the Primary Key (PK) on `cd_product_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02ceb3e4-176e-4eb0-8a38-4770f0d93309",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Importando recursos"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, current_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd89bfcc-b9cc-4a20-92b0-471d4ec03ea1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "dm_products"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, current_timestamp\n",
    "\n",
    "# 1. Defini√ß√µes de Caminho\n",
    "source_products = \"cat_tm_services_silver.db_logistics.tb_products\"\n",
    "source_translation = \"cat_tm_services_silver.db_logistics.tb_product_category_name_translation\"\n",
    "target_table = \"cat_tm_services_gold.db_logistics.dm_products\"\n",
    "\n",
    "# 2. Transforma√ß√£o e Cria√ß√£o\n",
    "df_products = spark.read.table(source_products)\n",
    "df_translation = spark.read.table(source_translation)\n",
    "\n",
    "dm_products = df_products.join(df_translation, \"nm_product_category_name\", \"left\").select(\n",
    "    col(\"cd_product_id\"),\n",
    "    col(\"nm_product_category_name_english\").alias(\"ds_product_category\"),\n",
    "    col(\"vl_product_weight_g\"),\n",
    "    col(\"vl_product_length_cm\"),\n",
    "    col(\"vl_product_height_cm\"),\n",
    "    col(\"vl_product_width_cm\")\n",
    ").withColumn(\"ts_gold_at\", current_timestamp())\n",
    "\n",
    "# Escrevemos a tabela primeiro\n",
    "dm_products.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(target_table)\n",
    "\n",
    "# 3. Aplica√ß√£o de Metadados (SQL Direto para maior compatibilidade com UI)\n",
    "print(f\"Applying Governance to {target_table}...\")\n",
    "\n",
    "# TAGS (Tente executar estas tr√™s linhas separadamente se o erro persistir)\n",
    "# No Databricks moderno, esta √© a sintaxe que preenche a coluna 'Tags' do UI\n",
    "spark.sql(f\"ALTER TABLE {target_table} SET TAGS ('quality' = 'gold', 'domain' = 'logistics', 'type' = 'dimension')\")\n",
    "\n",
    "# COMENT√ÅRIOS DE COLUNA\n",
    "spark.sql(f\"ALTER TABLE {target_table} ALTER COLUMN cd_product_id COMMENT 'Unique identifier for the product (MD5 Hash)'\")\n",
    "spark.sql(f\"ALTER TABLE {target_table} ALTER COLUMN ds_product_category COMMENT 'Product category name translated to English'\")\n",
    "spark.sql(f\"ALTER TABLE {target_table} ALTER COLUMN vl_product_weight_g COMMENT 'Product weight measured in grams'\")\n",
    "spark.sql(f\"ALTER TABLE {target_table} ALTER COLUMN vl_product_length_cm COMMENT 'Product length measured in centimeters'\")\n",
    "spark.sql(f\"ALTER TABLE {target_table} ALTER COLUMN vl_product_height_cm COMMENT 'Product height measured in centimeters'\")\n",
    "spark.sql(f\"ALTER TABLE {target_table} ALTER COLUMN vl_product_width_cm COMMENT 'Product width measured in centimeters'\")\n",
    "spark.sql(f\"ALTER TABLE {target_table} ALTER COLUMN ts_gold_at COMMENT 'Timestamp of Gold layer processing'\")\n",
    "\n",
    "# CONSTRAINTS\n",
    "spark.sql(f\"ALTER TABLE {target_table} ALTER COLUMN cd_product_id SET NOT NULL\")\n",
    "try:\n",
    "    spark.sql(f\"ALTER TABLE {target_table} ADD CONSTRAINT pk_dm_products PRIMARY KEY(cd_product_id) RELY\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"‚úÖ Process complete. Please REFRESH your browser to see tags in Catalog Explorer.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "nb_db_logistics_gold_dm_products",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
