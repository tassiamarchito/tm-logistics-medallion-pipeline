{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4283b4ee-1563-4e8a-a251-1929399d85d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Layer: Gold (Business)\n",
    "**Project:** Lean Logistics Data Pipeline  \n",
    "**Business Domain:** E-commerce (Olist Dataset)\\\n",
    "**Table Name:** `ft_sales`\n",
    "\n",
    "---\n",
    "## üìë Notebook Information\n",
    "| Version | Date | Author | Summary of Changes |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| v1.0 | 2026-02-20 | T√°ssia Marchito | Initial creation of Sales Fact table (`ft_sales`) with delivery KPIs. |\n",
    "| v1.1 | 2026-02-20 | T√°ssia Marchito | Refactored primary keys to `id_` prefix and added full column metadata. |\n",
    "\n",
    "---\n",
    "## üéØ Objectives\n",
    "This notebook assembles the central Fact table, aggregating sales metrics and calculating business performance KPIs.\n",
    "* **Refined Keys:** Standardized IDs using `id_` prefix for better downstream consumption.\n",
    "* **Metric Aggregation:** Combining order items, total payments, and review scores.\n",
    "* **KPI Calculation:** Deriving delivery lead time and estimated vs. actual delivery performance.\n",
    "* **Full Governance:** 100% column documentation and discovery tags for Unity Catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "241750f2-c62e-4728-8f7c-f0bcb69edb5d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Importando recursos"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, current_timestamp, datediff, sum as _sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "daa8071a-756f-42e4-9f83-36849ff1740f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "ft_sellers"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Configura√ß√µes de Origem e Destino\n",
    "silver_db = \"cat_tm_services_silver.db_logistics\"\n",
    "target_table = \"cat_tm_services_gold.db_logistics.ft_sales\"\n",
    "\n",
    "print(f\"üöÄ Starting the build for {target_table}...\")\n",
    "\n",
    "# 2. Carregamento das Tabelas Silver\n",
    "df_orders = spark.read.table(f\"{silver_db}.tb_orders\")\n",
    "df_items = spark.read.table(f\"{silver_db}.tb_order_items\")\n",
    "df_payments = spark.read.table(f\"{silver_db}.tb_order_payments\")\n",
    "df_reviews = spark.read.table(f\"{silver_db}.tb_order_reviews\")\n",
    "\n",
    "# 3. Pr√©-agrega√ß√£o de Pagamentos\n",
    "df_pay_agg = df_payments.groupBy(\"cd_order_id\").agg(_sum(\"vl_payment_value\").alias(\"vl_total_order\"))\n",
    "\n",
    "# 4. Constru√ß√£o da Fato\n",
    "ft_sales = df_items.join(df_orders, \"cd_order_id\", \"inner\") \\\n",
    "    .join(df_pay_agg, \"cd_order_id\", \"left\") \\\n",
    "    .join(df_reviews.select(\"cd_order_id\", \"vl_review_score\"), \"cd_order_id\", \"left\")\n",
    "\n",
    "# 5. Sele√ß√£o, Renomea√ß√£o e KPIs\n",
    "ft_sales_final = ft_sales.select(\n",
    "    col(\"cd_order_id\").alias(\"id_order\"),\n",
    "    col(\"cd_customer_id\").alias(\"id_customer\"),\n",
    "    col(\"cd_product_id\").alias(\"id_product\"),\n",
    "    col(\"cd_seller_id\").alias(\"id_seller\"),\n",
    "    col(\"ts_order_purchase\"),\n",
    "    col(\"ts_order_delivered_customer_date\").alias(\"ts_order_delivered_customer\"),\n",
    "    col(\"dt_order_estimated_delivery\"),\n",
    "    col(\"vl_price\"),\n",
    "    col(\"vl_freight_value\"),\n",
    "    col(\"vl_total_order\"),\n",
    "    col(\"vl_review_score\"),\n",
    "    datediff(col(\"ts_order_delivered_customer_date\"), col(\"ts_order_purchase\")).alias(\"nr_days_to_deliver\"),\n",
    "    datediff(col(\"dt_order_estimated_delivery\"), col(\"ts_order_delivered_customer_date\")).alias(\"nr_days_delivery_performance\")\n",
    ").withColumn(\"ts_gold_at\", current_timestamp())\n",
    "\n",
    "# 6. Escrita da Tabela\n",
    "ft_sales_final.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(target_table)\n",
    "\n",
    "# 7. Governan√ßa e Metadados Completos\n",
    "print(f\"üìù Applying tags and full metadata to {target_table}...\")\n",
    "\n",
    "# Table Tags\n",
    "spark.sql(f\"ALTER TABLE {target_table} SET TAGS ('quality' = 'gold', 'domain' = 'logistics', 'type' = 'fact')\")\n",
    "\n",
    "# Column Comments (Dicion√°rio de Dados Completo)\n",
    "spark.sql(f\"ALTER TABLE {target_table} ALTER COLUMN id_order COMMENT 'Unique identifier for the order'\")\n",
    "spark.sql(f\"ALTER TABLE {target_table} ALTER COLUMN id_customer COMMENT 'Unique identifier for the customer'\")\n",
    "spark.sql(f\"ALTER TABLE {target_table} ALTER COLUMN id_product COMMENT 'Unique identifier for the product'\")\n",
    "spark.sql(f\"ALTER TABLE {target_table} ALTER COLUMN id_seller COMMENT 'Unique identifier for the seller'\")\n",
    "spark.sql(f\"ALTER TABLE {target_table} ALTER COLUMN ts_order_purchase COMMENT 'Timestamp of when the order was placed'\")\n",
    "spark.sql(f\"ALTER TABLE {target_table} ALTER COLUMN ts_order_delivered_customer COMMENT 'Timestamp of actual delivery to customer'\")\n",
    "spark.sql(f\"ALTER TABLE {target_table} ALTER COLUMN dt_order_estimated_delivery COMMENT 'Estimated delivery date informed at purchase'\")\n",
    "spark.sql(f\"ALTER TABLE {target_table} ALTER COLUMN vl_price COMMENT 'Item price'\")\n",
    "spark.sql(f\"ALTER TABLE {target_table} ALTER COLUMN vl_freight_value COMMENT 'Shipping cost for the item'\")\n",
    "spark.sql(f\"ALTER TABLE {target_table} ALTER COLUMN vl_total_order COMMENT 'Total order value (sum of all payments for the order id)'\")\n",
    "spark.sql(f\"ALTER TABLE {target_table} ALTER COLUMN vl_review_score COMMENT 'Customer satisfaction score (1 to 5)'\")\n",
    "spark.sql(f\"ALTER TABLE {target_table} ALTER COLUMN nr_days_to_deliver COMMENT 'Number of days between purchase and actual delivery'\")\n",
    "spark.sql(f\"ALTER TABLE {target_table} ALTER COLUMN nr_days_delivery_performance COMMENT 'Days difference: estimated vs actual (positive is early, negative is late)'\")\n",
    "spark.sql(f\"ALTER TABLE {target_table} ALTER COLUMN ts_gold_at COMMENT 'Processing timestamp in the Gold layer'\")\n",
    "\n",
    "# Constraints (PK)\n",
    "spark.sql(f\"ALTER TABLE {target_table} ALTER COLUMN id_order SET NOT NULL\")\n",
    "try:\n",
    "    spark.sql(f\"ALTER TABLE {target_table} ADD CONSTRAINT pk_ft_sales PRIMARY KEY(id_order, id_product) RELY\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(f\"‚úÖ Fact Table {target_table} is now fully documented!\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "nb_db_logistics_gold_ft_sales",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
