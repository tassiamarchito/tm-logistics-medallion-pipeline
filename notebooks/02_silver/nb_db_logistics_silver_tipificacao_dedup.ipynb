{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "056d9997-3477-4217-aae2-b151361ed926",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Layer: Silver (Refined)\n",
    "**Project:** Lean Logistics Data Pipeline  \n",
    "**Business Domain:** E-commerce (Olist Dataset)\n",
    "\n",
    "---\n",
    "## üìë Notebook Information\n",
    "| Version | Date | Author | Summary of Changes |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| v1.0 | 2026-02-20 | T√°ssia Marchito | Initial ingestion from Bronze, schema enforcement, and PK constraints. |\n",
    "| v1.1 | 2026-02-20 | T√°ssia Marchito | Added `tb_order_items` with Decimal(10,2) for financial precision. |\n",
    "| v1.2 | 2026-02-20 | T√°ssia Marchito | Added Implemented `ts_` (timestamp) and `dt_` (date) prefixes for time-based columns. |\n",
    "| v2.0 | 2026-02-20 | T√°ssia Marchito | Implemented `try_cast` for fault tolerance and strict data quality filtering for `tb_order_reviews`. |\n",
    "\n",
    "---\n",
    "## üéØ Objectives\n",
    "The Silver layer represents the \"Single Source of Truth\". Our goal is to transform raw data into high-quality business entities.\n",
    "* **Schema Enforcement:** Strict data typing using `cd_`, `ts_`, `dt_`, `vl_`, and `nm_`/`ds_` prefixes.\n",
    "* **Fault Tolerance:** Usage of `try_cast` and `try_to_date` to handle malformed strings and column shifts from source APIs.\n",
    "* **Data Cleansing:** Filtering corrupted rows in `tb_order_reviews` by validating `review_id` length and `review_score` range.\n",
    "* **Governance:** Applying Unity Catalog constraints (PKs RELY) and removing redundant Bronze audit columns (`ts_ingestion`/`_ts_ingestion`).\n",
    "* **Standardization:** Ensuring all 9 tables are correctly cataloged and deduplicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8d9f4ba-d2ff-47dd-af27-ba977be73ecb",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Importando Functions"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, current_timestamp, trim, upper, to_timestamp, to_date, length, expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc26604d-f115-48c9-88c5-f2a8d0c1cc63",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Tratando tipifica√ß√£o e nomenclaturas"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Configura√ß√£o Exata fornecida\n",
    "silver_config = {\n",
    "    \"tb_orders\": {\n",
    "        \"pk\": [\"order_id\"], \n",
    "        \"ts\": [\"order_purchase_timestamp\", \"order_approved_at\", \"order_delivered_carrier_date\", \"order_delivered_customer_date\"], \n",
    "        \"dt\": [\"order_estimated_delivery_date\"], \n",
    "        \"vl\": []\n",
    "    },\n",
    "    \"tb_order_items\": {\n",
    "        \"pk\": [\"order_id\", \"order_item_id\"], \n",
    "        \"ts\": [\"shipping_limit_date\"], \n",
    "        \"dt\": [], \n",
    "        \"vl\": [\"price\", \"freight_value\"]\n",
    "    },\n",
    "    \"tb_order_reviews\": {\n",
    "        \"pk\": [\"review_id\"], \n",
    "        \"ts\": [\"review_answer_timestamp\"], \n",
    "        \"dt\": [\"review_creation_date\"], \n",
    "        \"vl\": [\"review_score\"]\n",
    "    },\n",
    "    \"tb_order_payments\": {\n",
    "        \"pk\": [\"order_id\", \"payment_sequential\"], \n",
    "        \"ts\": [], \n",
    "        \"dt\": [], \n",
    "        \"vl\": [\"payment_value\"]\n",
    "    },\n",
    "    \"tb_products\": {\n",
    "        \"pk\": [\"product_id\"], \n",
    "        \"ts\": [], \n",
    "        \"dt\": [], \n",
    "        \"vl\": [\"product_weight_g\", \"product_length_cm\", \"product_height_cm\", \"product_width_cm\"]\n",
    "    },\n",
    "    \"tb_customers\": {\n",
    "        \"pk\": [\"customer_id\"], \n",
    "        \"ts\": [], \n",
    "        \"dt\": [], \n",
    "        \"vl\": []\n",
    "    },\n",
    "    \"tb_sellers\": {\n",
    "        \"pk\": [\"seller_id\"], \n",
    "        \"ts\": [], \n",
    "        \"dt\": [], \n",
    "        \"vl\": []\n",
    "    },\n",
    "    \"tb_geolocation\": {\n",
    "        \"pk\": [\"geolocation_zip_code_prefix\", \"geolocation_lat\", \"geolocation_lng\"], \n",
    "        \"ts\": [], \n",
    "        \"dt\": [], \n",
    "        \"vl\": []\n",
    "    },\n",
    "    \"tb_product_category_name_translation\": {\n",
    "        \"pk\": [\"product_category_name\"], \n",
    "        \"ts\": [], \n",
    "        \"dt\": [], \n",
    "        \"vl\": []\n",
    "    }\n",
    "}\n",
    "\n",
    "def get_col_info(col_name, config):\n",
    "    c = col_name.lower()\n",
    "    # Prioridade para tipos definidos\n",
    "    if col_name in config[\"ts\"]: return f\"ts_{c.replace('_timestamp','').replace('_at','')}\", \"timestamp\"\n",
    "    if col_name in config[\"dt\"]: return f\"dt_{c.replace('_date','')}\", \"date\"\n",
    "    if col_name in config[\"vl\"]: return f\"vl_{c}\", \"decimal\"\n",
    "    \n",
    "    # Prefixos por padr√£o de nome\n",
    "    if any(x in c for x in [\"_id\", \"id\", \"_code\", \"_prefix\", \"sequential\", \"lat\", \"lng\"]):\n",
    "        return f\"cd_{c.replace('cd_', '')}\", \"string\"\n",
    "    \n",
    "    prefix = \"nm_\" if any(x in c for x in [\"name\", \"city\", \"state\"]) else \"ds_\"\n",
    "    return f\"{prefix}{c}\", \"string\"\n",
    "\n",
    "# 2. Loop de Processamento\n",
    "for table, cfg in silver_config.items():\n",
    "    source = f\"cat_tm_services_bronze.db_logistics.{table}\"\n",
    "    target = f\"cat_tm_services_silver.db_logistics.{table}\"\n",
    "    \n",
    "    print(f\"üíé Refining Silver: {table}\")\n",
    "    try:\n",
    "        df = spark.read.table(source)\n",
    "        \n",
    "        # --- ETAPA DE QUALIDADE BLINDADA ---\n",
    "        if table == \"tb_order_reviews\":\n",
    "            # Usamos try_cast diretamente no filtro para evitar o erro de malformed input\n",
    "            # Se o valor n√£o for um inteiro v√°lido (como uma data), o try_cast retorna NULL\n",
    "            # e o filtro descarta a linha sem quebrar o processo.\n",
    "            df = df.filter(length(col(\"review_id\")) == 32) \\\n",
    "                   .filter(expr(\"try_cast(review_score as int)\").isin(1, 2, 3, 4, 5))\n",
    "            print(f\"   ‚ö†Ô∏è Qualidade: Linhas malformadas neutralizadas.\")\n",
    "\n",
    "        # --- MAPEAMENTO E TRANSFORMA√á√ÉO ---\n",
    "        transform_exprs = []\n",
    "        new_pk_list = []\n",
    "        \n",
    "        audit_cols = [\"ts_ingestion\", \"_ts_ingestion\", \"_source_file\"]\n",
    "        business_cols = [c for c in df.columns if c not in audit_cols]\n",
    "        \n",
    "        for c in business_cols:\n",
    "            new_name, d_type = get_col_info(c, cfg)\n",
    "            if c in cfg[\"pk\"]: new_pk_list.append(new_name)\n",
    "            \n",
    "            # Casts seguros para colunas de destino\n",
    "            if d_type == \"timestamp\":\n",
    "                c_expr = expr(f\"try_to_timestamp({c})\")\n",
    "            elif d_type == \"date\":\n",
    "                c_expr = expr(f\"try_to_date({c})\")\n",
    "            elif d_type == \"decimal\":\n",
    "                # Tamb√©m usamos try_cast aqui para seguran√ßa total\n",
    "                c_expr = expr(f\"try_cast({c} as decimal(10,2))\")\n",
    "            else:\n",
    "                c_expr = upper(trim(col(c)))\n",
    "            \n",
    "            transform_exprs.append(c_expr.alias(new_name))\n",
    "\n",
    "        # --- GERA√á√ÉO DA SILVER E DEDUPLICA√á√ÉO ---\n",
    "        df_silver = df.select(*transform_exprs) \\\n",
    "                      .dropDuplicates(new_pk_list) \\\n",
    "                      .withColumn(\"ts_silver_at\", current_timestamp())\n",
    "\n",
    "        # Persist√™ncia\n",
    "        df_silver.write.format(\"delta\").mode(\"overwrite\") \\\n",
    "                 .option(\"overwriteSchema\", \"true\").saveAsTable(target)\n",
    "        \n",
    "        # Constraints\n",
    "        pk_sql = \", \".join(new_pk_list)\n",
    "        for c_pk in new_pk_list:\n",
    "            spark.sql(f\"ALTER TABLE {target} ALTER COLUMN {c_pk} SET NOT NULL\")\n",
    "        spark.sql(f\"ALTER TABLE {target} ADD CONSTRAINT pk_{table}_slv PRIMARY KEY({pk_sql}) RELY\")\n",
    "        \n",
    "        print(f\"   ‚úÖ Sucesso!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Erro em {table}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1edc317d-c003-4bb1-a94d-f54cd655dab9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "nb_db_logistics_silver_tipificacao_dedup",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
